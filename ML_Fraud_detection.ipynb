{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyMvfgarAK949V3rk3v7snQG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ben854719/Biometric-Aware-Fraud-Risk-Dashboard-with-Agentic-AI/blob/main/ML_Fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blDhVerASIzL",
        "outputId": "cf35293d-b96f-4799-b525-70c4062a8344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install polars"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b595b98",
        "outputId": "4fa0bfd3-d39a-4f9c-8f99-ec88c481b909"
      },
      "source": [
        "# Import the dataset for the Stock.\n",
        "INDEX_CA_XTSE_GSPTSE = pl.read_csv('INDEX_CA_XTSE_GSPTSE.csv')\n",
        "\n",
        "# Convert Polars DataFrame to Pandas DataFrame\n",
        "df = INDEX_CA_XTSE_GSPTSE.to_pandas()\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values before handling:\")\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values before handling:\n",
            "Date     0\n",
            "Open     0\n",
            "High     0\n",
            "Low      0\n",
            "Close    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6YL1jzrVFGT",
        "outputId": "8b06525f-10a7-4eda-f8fd-059099c9ba0e"
      },
      "source": [
        "# Import the dataset for the Stock.\n",
        "INDEX_CA_XTSE_GSPTSE = pl.read_csv('INDEX_CA_XTSE_GSPTSE.csv')\n",
        "\n",
        "# Convert Polars DataFrame to Pandas DataFrame\n",
        "df = INDEX_CA_XTSE_GSPTSE.to_pandas()\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values before handling:\")\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values before handling:\n",
            "Date     0\n",
            "Open     0\n",
            "High     0\n",
            "Low      0\n",
            "Close    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEfQCfACVG55",
        "outputId": "3b9c1ba1-7bd0-472c-9390-6bb22033d189"
      },
      "source": [
        "import polars as pl\n",
        "\n",
        "# Import the dataset for the Stock.\n",
        "INDEX_CA_XTSE_GSPTSE = pl.read_csv('INDEX_CA_XTSE_GSPTSE.csv')\n",
        "\n",
        "# Convert Polars DataFrame to Pandas DataFrame\n",
        "df = INDEX_CA_XTSE_GSPTSE.to_pandas()\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values before handling:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Handle missing values: fill NaN with the mean of the column\n",
        "for column in df.columns:\n",
        "    if df[column].isnull().any():\n",
        "        if df[column].dtype in ['int64', 'float64']:\n",
        "            df[column].fillna(df[column].mean(), inplace=True)\n",
        "        else:\n",
        "            # For non-numeric columns, fill with a placeholder or mode,\n",
        "            # depending on the nature of the data and task.\n",
        "            # For this dataset, assuming numerical columns primarily need imputation.\n",
        "            pass # No non-numeric columns with NaNs expected based on typical stock data\n",
        "\n",
        "print(\"\\nMissing values after handling:\")\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values before handling:\n",
            "Date     0\n",
            "Open     0\n",
            "High     0\n",
            "Low      0\n",
            "Close    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values after handling:\n",
            "Date     0\n",
            "Open     0\n",
            "High     0\n",
            "Low      0\n",
            "Close    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7ffc997",
        "outputId": "bcfad21e-e26b-4cbd-bdd4-79a44bb9b693"
      },
      "source": [
        "# Identify categorical columns (assuming 'Date' is the only one for now)\n",
        "categorical_cols = ['Date']\n",
        "\n",
        "# Identify numerical columns (assuming Open, High, Low, Close after conversion)\n",
        "numerical_cols = ['Open', 'High', 'Low', 'Close']\n",
        "\n",
        "# Convert numerical columns from string to numeric, handling commas\n",
        "for col in numerical_cols:\n",
        "    df[col] = df[col].str.replace(',', '').astype(float)\n",
        "\n",
        "# Encode categorical columns - Label Encoding for 'Date' as it might be used as a feature representing time order\n",
        "# Although for fraud detection on stock data, Date might be used differently or not at all as a direct feature.\n",
        "# For now, applying Label Encoding as a general preprocessing step for a categorical column.\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df['Date_encoded'] = label_encoder.fit_transform(df['Date'])\n",
        "\n",
        "# Drop the original 'Date' column\n",
        "df = df.drop('Date', axis=1)\n",
        "categorical_cols.remove('Date') # Update the list of categorical columns if needed\n",
        "\n",
        "# Identify numerical columns after handling 'Date'\n",
        "numerical_cols = ['Open', 'High', 'Low', 'Close', 'Date_encoded']\n",
        "\n",
        "# Scale the numerical columns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "# Assuming 'Close' is the target variable for demonstration, though fraud detection might use a different target\n",
        "X = df.drop('Close', axis=1)\n",
        "y = df['Close']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Preprocessing steps completed.\")\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing steps completed.\n",
            "Shape of X_train: (16, 4)\n",
            "Shape of X_test: (4, 4)\n",
            "Shape of y_train: (16,)\n",
            "Shape of y_test: (4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eace09fd",
        "outputId": "3b861eb5-df30-450e-a6ec-603bae50916a"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class FraudDetectionModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(FraudDetectionModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1) # Assuming a single output for regression or binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Get the input dimension from the training data\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "# Instantiate the model\n",
        "model = FraudDetectionModel(input_dim)\n",
        "\n",
        "print(\"Neural network model defined and instantiated.\")\n",
        "print(model)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network model defined and instantiated.\n",
            "FraudDetectionModel(\n",
            "  (fc1): Linear(in_features=4, out_features=64, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsySuNASVRNr",
        "outputId": "e84ea531-d4a0-49e3-e4e9-4eb9e244f4f4"
      },
      "source": [
        "# Import necessary PyTorch modules\n",
        "import torch.nn as nn\n",
        "\n",
        "class FraudDetectionModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(FraudDetectionModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1) # Assuming a single output for regression or binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Get the input dimension from the training data\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "# Instantiate the model\n",
        "model = FraudDetectionModel(input_dim)\n",
        "\n",
        "print(\"Neural network model defined and instantiated.\")\n",
        "print(model)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network model defined and instantiated.\n",
            "FraudDetectionModel(\n",
            "  (fc1): Linear(in_features=4, out_features=64, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44b1533c",
        "outputId": "d417d686-52b2-4e66-80e0-af7347e97527"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# 1. Convert the training data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1) # Add a dimension for the output\n",
        "\n",
        "# 2. Define the loss function (Mean Squared Error for regression)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# 3. Define the optimizer (Adam)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 4. Set the number of training epochs and the batch size\n",
        "num_epochs = 100\n",
        "batch_size = 16 # Or another appropriate batch size\n",
        "\n",
        "# 5. Implement the training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Iterate over the training data in batches\n",
        "    for i in range(0, len(X_train_tensor), batch_size):\n",
        "        batch_X = X_train_tensor[i:i+batch_size]\n",
        "        batch_y = y_train_tensor[i:i+batch_size]\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(batch_X)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "    # Optional: Print the loss every epoch\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"Training complete.\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.8275\n",
            "Epoch [20/100], Loss: 0.5191\n",
            "Epoch [30/100], Loss: 0.2896\n",
            "Epoch [40/100], Loss: 0.1823\n",
            "Epoch [50/100], Loss: 0.1365\n",
            "Epoch [60/100], Loss: 0.0979\n",
            "Epoch [70/100], Loss: 0.0730\n",
            "Epoch [80/100], Loss: 0.0586\n",
            "Epoch [90/100], Loss: 0.0509\n",
            "Epoch [100/100], Loss: 0.0458\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "380add65",
        "outputId": "8b64937f-031d-4108-fd9b-a613c5d414e8"
      },
      "source": [
        "# 1. Convert the test feature data X_test into a PyTorch tensor with float32 data type.\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "\n",
        "# 2. Convert the test target data y_test into a PyTorch tensor with float32 data type and add an extra dimension using unsqueeze(1).\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# 3. Set the model to evaluation mode using model.eval(). This disables dropout and batch normalization if present.\n",
        "model.eval()\n",
        "\n",
        "# 4. Disable gradient calculation using torch.no_grad() as gradients are not needed for inference.\n",
        "with torch.no_grad():\n",
        "    # 5. Pass the test feature tensor through the trained model to get predictions.\n",
        "    predictions = model(X_test_tensor)\n",
        "\n",
        "    # 6. Calculate the Mean Squared Error (MSE) between the model's predictions and the actual test target tensor using the criterion.\n",
        "    test_loss = criterion(predictions, y_test_tensor)\n",
        "\n",
        "# 7. Print the calculated MSE on the test set.\n",
        "print(f'Mean Squared Error on Test Set: {test_loss.item():.4f}')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error on Test Set: 0.1285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5rjy6IVVmrO",
        "outputId": "09a12568-645f-4e58-8d36-5824a4d7e5fa"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Prepare a new data point or a set of new data points for prediction.\n",
        "# This data should have the same features as the training data (Open, High, Low, Date_encoded)\n",
        "# Let's create a sample new data point as a pandas DataFrame\n",
        "new_data = pd.DataFrame({\n",
        "    'Open': [30000.00],\n",
        "    'High': [30100.00],\n",
        "    'Low': [29900.00],\n",
        "    'Date_encoded': [20] # Assuming a new date value\n",
        "})\n",
        "\n",
        "# Ensure the new data has the same columns in the same order as the training data\n",
        "new_data = new_data[X_train.columns]\n",
        "\n",
        "# 2. Preprocess the new data using the same StandardScaler instance used for the training data.\n",
        "# We need to re-fit the scaler on the entire original dataframe 'df' to ensure consistent scaling.\n",
        "# This is because the original scaler was fit on the entire 'df' before splitting.\n",
        "# Let's re-fit the scaler on the numerical columns of the original dataframe 'df'.\n",
        "# Assuming 'df' from the previous steps is available and contains the original scaled data.\n",
        "# We need the original unscaled data to fit the scaler correctly.\n",
        "# Let's assume we have the original unscaled data available in a variable called 'original_df'.\n",
        "# If not, we would need to load and preprocess the original data again up to the scaling step.\n",
        "\n",
        "# Since 'df' in the kernel is already scaled, we need to go back to the unscaled data.\n",
        "# Let's assume 'INDEX_CA_XTSE_GSPTSE' is the original polars dataframe.\n",
        "# Convert it to pandas and clean it to get the unscaled numerical data.\n",
        "original_df_unscaled = INDEX_CA_XTSE_GSPTSE.to_pandas()\n",
        "\n",
        "# Convert numerical columns from string to numeric, handling commas\n",
        "numerical_cols_unscaled = ['Open', 'High', 'Low', 'Close']\n",
        "for col in numerical_cols_unscaled:\n",
        "    original_df_unscaled[col] = original_df_unscaled[col].str.replace(',', '').astype(float)\n",
        "\n",
        "# Encode 'Date' column\n",
        "# label_encoder_unscaled = LabelEncoder() # LabelEncoder is already imported\n",
        "original_df_unscaled['Date_encoded'] = label_encoder.fit_transform(original_df_unscaled['Date'])\n",
        "\n",
        "# Drop the original 'Date' column\n",
        "original_df_unscaled = original_df_unscaled.drop('Date', axis=1)\n",
        "\n",
        "# Identify numerical columns for scaling\n",
        "numerical_cols_scaling = ['Open', 'High', 'Low', 'Date_encoded'] # Exclude 'Close' as it's the target\n",
        "\n",
        "# Create and fit the scaler on the unscaled training features\n",
        "# scaler_predict = StandardScaler() # StandardScaler is already imported\n",
        "scaler_predict = StandardScaler()\n",
        "scaler_predict.fit(original_df_unscaled[numerical_cols_scaling])\n",
        "\n",
        "# Apply the fitted scaler to the new data\n",
        "new_data_scaled = scaler_predict.transform(new_data)\n",
        "\n",
        "# Convert the scaled new data back to a DataFrame to maintain column names\n",
        "new_data_scaled_df = pd.DataFrame(new_data_scaled, columns=numerical_cols_scaling)\n",
        "\n",
        "\n",
        "# 3. Convert the preprocessed new data into a PyTorch tensor with torch.float32 data type.\n",
        "new_data_tensor = torch.tensor(new_data_scaled_df.values, dtype=torch.float32)\n",
        "\n",
        "# 4. Ensure the model is in evaluation mode using model.eval().\n",
        "model.eval()\n",
        "\n",
        "# 5. Disable gradient calculation using torch.no_grad().\n",
        "with torch.no_grad():\n",
        "    # 6. Pass the new data tensor through the trained model to get predictions using the model() method.\n",
        "    predictions = model(new_data_tensor)\n",
        "\n",
        "# 7. Convert the output tensor back to a NumPy array or Pandas DataFrame for easier interpretation.\n",
        "predictions_np = predictions.numpy()\n",
        "\n",
        "print(\"Prediction on new data:\")\n",
        "print(predictions_np)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction on new data:\n",
            "[[-1.1876674]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install polars plotly pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "D9JP_mbuaScf",
        "outputId": "530eecbf-c062-4a27-e317-8a9e8eff64b7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (1.25.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "# 🧪 Simulated tensors (replace with your model outputs)\n",
        "y_test_tensor = np.array([100, 102, 105, 103, 107])\n",
        "predictions = np.array([101, 101, 106, 102, 108])\n",
        "\n",
        "# 🎭 Simulated sentiment scores (range: 0 = negative, 1 = positive)\n",
        "sentiment_tensor = np.random.rand(len(y_test_tensor))\n",
        "\n",
        "# 🧠 Create Polars DataFrame\n",
        "df = pl.DataFrame({\n",
        "    \"Actual Closing Price\": y_test_tensor,\n",
        "    \"Predicted Closing Price\": predictions,\n",
        "    \"Sentiment Score\": sentiment_tensor\n",
        "})\n",
        "\n",
        "# 🏷️ Add sentiment categories\n",
        "def categorize_sentiment(score):\n",
        "    if score < 0.4:\n",
        "        return \"Negative\"\n",
        "    elif score < 0.7:\n",
        "        return \"Neutral\"\n",
        "    else:\n",
        "        return \"Positive\"\n",
        "\n",
        "df = df.with_columns([\n",
        "    pl.col(\"Sentiment Score\").map_elements(categorize_sentiment, return_dtype=pl.Utf8).alias(\"Sentiment\")\n",
        "])\n",
        "\n",
        "# 🔁 Convert to Pandas for Plotly\n",
        "plot_data = df.to_pandas()\n",
        "plot_data[\"Index\"] = plot_data.index\n",
        "\n",
        "# 📈 Line plot: Actual vs Predicted\n",
        "fig = px.line(plot_data, x=\"Index\",\n",
        "              y=[\"Actual Closing Price\", \"Predicted Closing Price\"],\n",
        "              title=\"Actual vs Predicted Prices with Sentiment Overlay\")\n",
        "\n",
        "# 🟢 Sentiment scatter overlay\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=plot_data[\"Index\"],\n",
        "    y=plot_data[\"Predicted Closing Price\"],\n",
        "    mode=\"markers\",\n",
        "    marker=dict(size=10,\n",
        "                color=plot_data[\"Sentiment Score\"],\n",
        "                colorscale=\"RdYlGn\",\n",
        "                showscale=True),\n",
        "    name=\"Sentiment Score\"\n",
        "))\n",
        "\n",
        "# 🛠️ Layout tweaks\n",
        "fig.update_layout(xaxis_title=\"Test Data Index\",\n",
        "                  yaxis_title=\"Closing Price\",\n",
        "                  legend_title=\"Price Type\")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "rzfScD2GdfEf",
        "outputId": "36253853-f040-41ba-8578-3b70b3c47ae0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"1c7157e7-0b56-422d-9568-d31aae987886\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1c7157e7-0b56-422d-9568-d31aae987886\")) {                    Plotly.newPlot(                        \"1c7157e7-0b56-422d-9568-d31aae987886\",                        [{\"hovertemplate\":\"variable=Actual Closing Price\\u003cbr\\u003eIndex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Actual Closing Price\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Actual Closing Price\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4],\"xaxis\":\"x\",\"y\":[100,102,105,103,107],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"variable=Predicted Closing Price\\u003cbr\\u003eIndex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Predicted Closing Price\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Predicted Closing Price\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4],\"xaxis\":\"x\",\"y\":[101,101,106,102,108],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"marker\":{\"color\":[0.0965897870353386,0.039853432593219607,0.1441838155659957,0.2917467137383012,0.7478150526816092],\"colorscale\":[[0.0,\"rgb(165,0,38)\"],[0.1,\"rgb(215,48,39)\"],[0.2,\"rgb(244,109,67)\"],[0.3,\"rgb(253,174,97)\"],[0.4,\"rgb(254,224,139)\"],[0.5,\"rgb(255,255,191)\"],[0.6,\"rgb(217,239,139)\"],[0.7,\"rgb(166,217,106)\"],[0.8,\"rgb(102,189,99)\"],[0.9,\"rgb(26,152,80)\"],[1.0,\"rgb(0,104,55)\"]],\"showscale\":true,\"size\":10},\"mode\":\"markers\",\"name\":\"Sentiment Score\",\"x\":[0,1,2,3,4],\"y\":[101,101,106,102,108],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Test Data Index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Closing Price\"}},\"legend\":{\"title\":{\"text\":\"Price Type\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Actual vs Predicted Prices with Sentiment Overlay\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1c7157e7-0b56-422d-9568-d31aae987886');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Explanation:\n",
        "\n",
        "This graph compares actual and predicted closing prices across the test sessions, with sentiment scores overlaid to highlight emotional volatility that may influence prediction accuracy or signal elevated fraud risk.\n"
      ],
      "metadata": {
        "id": "Re1q2gEwdmiV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}