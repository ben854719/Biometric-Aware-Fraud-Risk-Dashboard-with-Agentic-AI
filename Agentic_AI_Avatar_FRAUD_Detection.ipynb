{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMueKm5d6v7EKGp6X8LVjk6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ben854719/Biometric-Aware-Fraud-Risk-Dashboard-with-Agentic-AI/blob/main/Agentic_AI_Avatar_FRAUD_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ex7UHmAQzAXM"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade langchain-google-genai google-generativeai\n",
        "!pip install --upgrade langchain-google-genai google-generativeai langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"mcp[cli]\"\n",
        "from mcp.server.fastmcp import FastMCP\n",
        "\n",
        "mcp = FastMCP(\"GeminiTools\")\n",
        "\n",
        "@mcp.tool()\n",
        "def search(query: str) -> list:\n",
        "    # Your search logic here\n",
        "    return [\"Result 1\", \"Result 2\"]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6LrNPUkk0rH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd mcp-server-demo\n",
        "!ls"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WHBTdze80wm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd mcp-server-demo && uv add langchain-google-genai langgraph"
      ],
      "metadata": {
        "id": "tv9QMKu105N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.tools import Tool\n",
        "from langgraph.graph import StateGraph, END\n",
        "from IPython.display import display, HTML\n",
        "from typing import TypedDict\n",
        "import os\n",
        "import random\n",
        "from mcp.server.fastmcp import FastMCP\n",
        "from google.colab import userdata\n",
        "\n",
        "# Import API Key.\n",
        "api_key = userdata.get(\"Ben856\")  # Or paste your key directly\n",
        "if not api_key:\n",
        "    raise ValueError(\"Ben856 secret not found. Please set your API key in Colab Secrets.\")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "\n",
        "# Ini Gemini Model\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", api_key=api_key)\n",
        "prompt = ChatPromptTemplate.from_template(\"Respond confidently to: {input}\")\n",
        "chain = prompt | llm\n",
        "\n",
        "#  Dynamic HeyGen Video Selector.\n",
        "def select_heygen_url(response_text: str) -> str:\n",
        "    if \"onboarding\" in response_text.lower():\n",
        "        return \"https://app.heygen.com/videos/your_onboarding_video_id\"\n",
        "    elif \"risk\" in response_text.lower() or \"concern\" in response_text.lower():\n",
        "        return \"https://app.heygen.com/videos/your_fallback_video_id\"\n",
        "    else:\n",
        "        return \"https://app.heygen.com/videos/cd56d01dad544759ba6e872b093a32d8\"  # Default\n",
        "\n",
        "# üé¨ Avatar Node (Colab-safe link preview)\n",
        "def avatar_node(input_text):\n",
        "    print(\"Avatar says:\", input_text)\n",
        "    heygen_url = select_heygen_url(input_text)\n",
        "    display(HTML(f'<a href=\"{heygen_url}\" target=\"_blank\">‚ñ∂Ô∏è Click to view avatar response</a>'))\n",
        "    return {\"avatar_output\": f\"Avatar says: {input_text}\"}\n",
        "\n",
        "# üõ†Ô∏è Optional Tool Wrapper\n",
        "avatar_tool = Tool.from_function(\n",
        "    func=avatar_node,\n",
        "    name=\"AvatarSpeaker\",\n",
        "    description=\"Trigger avatar speech\"\n",
        ")\n",
        "\n",
        "# üß© Workflow Nodes\n",
        "def gemini_node(state: \"WorkflowState\"):\n",
        "    response = chain.invoke({\"input\": state[\"input\"]})\n",
        "    state[\"response\"] = response.content\n",
        "    return state\n",
        "\n",
        "def emotion_node(state: \"WorkflowState\"):\n",
        "    text = state[\"response\"]\n",
        "    if \"confident\" in text or \"welcome\" in text:\n",
        "        state[\"emotion\"] = \"positive\"\n",
        "    elif \"concern\" in text or \"risk\" in text:\n",
        "        state[\"emotion\"] = \"negative\"\n",
        "    else:\n",
        "        state[\"emotion\"] = \"neutral\"\n",
        "    return state\n",
        "\n",
        "def fallback_node(state: \"WorkflowState\"):\n",
        "    if state[\"emotion\"] == \"negative\":\n",
        "        state[\"response\"] = \"Fallback message: Let's review the risk indicators together.\"\n",
        "    return state\n",
        "\n",
        "def onboarding_node(state: \"WorkflowState\"):\n",
        "    if \"onboarding\" in state[\"response\"].lower():\n",
        "        state[\"response\"] = \"Welcome aboard! Here's how we ensure compliance and clarity.\"\n",
        "    return state\n",
        "\n",
        "def compliance_score_node(state: \"WorkflowState\"):\n",
        "    score = random.randint(70, 100)\n",
        "    state[\"response\"] += f\" (Compliance Score: {score})\"\n",
        "    return state\n",
        "\n",
        "def avatar_speak_node(state: \"WorkflowState\"):\n",
        "    avatar_result = avatar_node(state[\"response\"])\n",
        "    state[\"avatar_output\"] = avatar_result[\"avatar_output\"]\n",
        "    return state\n",
        "\n",
        "# üß† State Schema\n",
        "class WorkflowState(TypedDict):\n",
        "    input: str\n",
        "    response: str\n",
        "    emotion: str\n",
        "    avatar_output: str\n",
        "\n",
        "# üîÑ LangGraph Flow\n",
        "graph = StateGraph(WorkflowState)\n",
        "graph.add_node(\"gemini\", gemini_node)\n",
        "graph.add_node(\"emotion\", emotion_node)\n",
        "graph.add_node(\"fallback\", fallback_node)\n",
        "graph.add_node(\"onboarding\", onboarding_node)\n",
        "graph.add_node(\"compliance_score\", compliance_score_node)\n",
        "graph.add_node(\"avatar_speak\", avatar_speak_node)\n",
        "\n",
        "graph.set_entry_point(\"gemini\")\n",
        "graph.add_edge(\"gemini\", \"emotion\")\n",
        "graph.add_edge(\"emotion\", \"fallback\")\n",
        "graph.add_edge(\"fallback\", \"onboarding\")\n",
        "graph.add_edge(\"onboarding\", \"compliance_score\")\n",
        "graph.add_edge(\"compliance_score\", \"avatar_speak\")\n",
        "graph.add_edge(\"avatar_speak\", END)\n",
        "\n",
        "flow = graph.compile()\n",
        "\n",
        "# üöÄ Run the Flow\n",
        "initial_state = {\"input\": \"Generate a confident greeting for onboarding and fraud detection\"}\n",
        "flow.invoke(initial_state)"
      ],
      "metadata": {
        "id": "d-UX7T9NzX6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}